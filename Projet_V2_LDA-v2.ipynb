{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:blue; font-style:bold\"><br>\n",
    "Projet 6 :<br><br>\n",
    "Catégorisez automatiquement des questions<br><br>\n",
    "</p><br>\n",
    "\n",
    "* **Data Source / Data Source :** \n",
    "    - Data :\n",
    "        - Outils d'extraction de data : https://data.stackexchange.com/stackoverflow\n",
    "        - Script : https://github.com/EricJacquesPro/TextCategorization/blob/master/SQL/ExtractionDonnees.sql\n",
    "    - Source Python : https://github.com/EricJacquesPro/TextCategorization\n",
    "* **Description / Description : ** Projet 6 de la formation Data Scientist Proposée par OpenClassroom\n",
    "    - Analyse LDA\n",
    "    - Entrainement LDA\n",
    "* **Auteur / Author : ** Eric JACQUES \n",
    "* **Date : ** 18/07/2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(0, './Python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naru_\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "python class for the data engineering (reading, cleaning, training...)\n",
    "localised in ./Python\n",
    "'''\n",
    "from tagText import TagText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/\n",
      "QuestionVsTags.csv\n"
     ]
    }
   ],
   "source": [
    "tagText = TagText()\n",
    "print(tagText.urlDirectory)#folder for cvs file generated by SQL query (cf. I) \n",
    "print(tagText.fileName)#name of the cvs file generated by SQL query (cf. I)\n",
    "data_question = tagText.read_source()\n",
    "data_question.head()\n",
    "\n",
    "tagText.nombre_post_entree = 50000\n",
    "tagText.precision = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = data_question['body'].apply(tagText.preprocessing)\n",
    "print(data_preprocessed[1:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\"><br>\n",
    "III.2 - Data - Bag of words - TF-IDF</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\"><br>\n",
    "IV.2-a - Data - Tag generator - Unsupervised - LDA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfsTrain, perfsValidation = tagText.lda_find_topic_number(\n",
    "                    data_preprocessed,\n",
    "                    5,\n",
    "                    81,\n",
    "                    2\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(perfsTrain))\n",
    "print(len(perfsValidation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(perfsTrain))\n",
    "print(max(perfsValidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mini=min(perfsTrain)\n",
    "#print(perfs)\n",
    "#print(perfs-mini)\n",
    "x = range(5,81,2)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "perfs_normalized = scale( perfsTrain, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "x_normalized = scale( x, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "\n",
    "plt.bar(x, perfsTrain)\n",
    "plt.ylabel(\"Performance\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance by number of topics\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(x, perfs_normalized)\n",
    "plt.ylabel(\"Performance normalized\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance normalized by number of topics\")\n",
    "plt.show()\n",
    "\n",
    "perfs_topic_optimized = np.add(x_normalized, perfs_normalized)\n",
    "plt.bar(x, perfs_topic_optimized)\n",
    "plt.ylabel(\"Performance normalized + number of topic normalized\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance optimized by number of topics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mini=min(perfsValidation)\n",
    "#print(perfs)\n",
    "#print(perfs-mini)\n",
    "x = range(5,81,2)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "perfs_normalized = scale( perfsValidation, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "x_normalized = scale( x, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "\n",
    "plt.bar(x, perfsValidation)\n",
    "plt.ylabel(\"Performance\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance by number of topics\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(x, perfs_normalized)\n",
    "plt.ylabel(\"Performance normalized\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance normalized by number of topics\")\n",
    "plt.show()\n",
    "\n",
    "perfs_topic_optimized = np.add(x_normalized, perfs_normalized)\n",
    "plt.bar(x, perfs_topic_optimized)\n",
    "plt.ylabel(\"Performance normalized + number of topic normalized\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"performance optimized by number of topics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def lda_predict(\n",
    "        model,\n",
    "        text,\n",
    "        lda,\n",
    "        lda_df_topic_keywords,\n",
    "        lda_tf_vectorizer,\n",
    "        no_top_words\n",
    "    ):\n",
    "        '''\n",
    "        predict tag form text in function of lda, topic ad tf vectorizer\n",
    "        '''\n",
    "        text = [text]\n",
    "        mytext = lda_tf_vectorizer.transform(text)\n",
    "        lda_topic_probability_scores = lda.transform(mytext)\n",
    "        lda_topic = lda_df_topic_keywords.iloc[\n",
    "            tagText.np.argmax(lda_topic_probability_scores),\n",
    "            :\n",
    "        ].values.tolist()\n",
    "        topic_array = model.np.array(lda_topic)\n",
    "        lda_feature_names = lda_tf_vectorizer.get_feature_names()\n",
    "        \"\"\"\n",
    "        print(lda_topic)\n",
    "        print(topic_array.argsort())\n",
    "        print(lda_feature_names)\n",
    "        \"\"\"\n",
    "        return (\n",
    "            \" \".join(\n",
    "                        [\n",
    "                            lda_feature_names[i]\n",
    "                            for i in topic_array.argsort()\n",
    "                            [\n",
    "                                :-no_top_words - 1:-1\n",
    "                            ]\n",
    "                        ]\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tagText, df_topic_keywords, tf_vectorizer = tagText.lda_prepare_tag(data_preprocessed, 32)\n",
    "\n",
    "print(lda_predict(tagText, 'I cannot intall a git repository. I try github and gitlab', lda_tagText, df_topic_keywords, tf_vectorizer, 5))\n",
    "print(tagText.lda_predict( \"How to cast number as integer in java\", lda_tagText, df_topic_keywords, tf_vectorizer, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(lda_predict(tagText, 'I cannot intall a git repository. I try github and gitlab', lda_tagText, df_topic_keywords, tf_vectorizer, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tagText.lda_predict( \"How to cast number as integer in java\", lda_tagText, df_topic_keywords, tf_vectorizer, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tagText.lda_predict( \"How to cast number as integer in java\", lda_tagText, df_topic_keywords, tf_vectorizer, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(lda_tagText, 'lda.joblib',0)\n",
    "dump(df_topic_keywords, 'df_lda_topic_keywords.joblib',0)\n",
    "dump(tf_vectorizer, 'tf_lda_vectorizer.joblib',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic :\", topic_idx, \":\" )\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 5\n",
    "print('Topics : ')\n",
    "display_topics(lda_tagText, tf_vectorizer.get_feature_names(), no_top_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Topics From working class : ')\n",
    "tagText.display_topics(lda_tagText, tf_vectorizer.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
